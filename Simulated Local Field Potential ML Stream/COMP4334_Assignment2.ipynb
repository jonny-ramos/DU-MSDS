{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf70a0d8-4c0e-4baf-bbeb-4cc61b098ef3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n50\n"
     ]
    }
   ],
   "source": [
    "# Jonathan Ramos\n",
    "# COMP4334 Assignment 2\n",
    "# 11/15/2023\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType, TimestampType\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, Bucketizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "HPC_hf_schema = StructType(\\\n",
    "    [StructField('index', LongType(), True), \\\n",
    "     StructField('trial_n', StringType(), True), \\\n",
    "     StructField('HPC_beta_hi_e', DoubleType(), True), \\\n",
    "     StructField('HPC_beta_hi_l', DoubleType(), True), \\\n",
    "     StructField('HPC_gamma_lo_e', DoubleType(), True), \\\n",
    "     StructField('HPC_gamma_lo_l', DoubleType(), True), \\\n",
    "     StructField('HPC_gamma_mid_e', DoubleType(), True), \\\n",
    "     StructField('HPC_gamma_mid_l', DoubleType(), True), \\\n",
    "     StructField('HPC_gamma_hi_e', DoubleType(), True), \\\n",
    "     StructField('HPC_gamma_hi_l', DoubleType(), True), \\\n",
    "     ])\n",
    "\n",
    "HPC_lf_schema = StructType(\\\n",
    "    [StructField('index', LongType(), True), \\\n",
    "     StructField('trial_n', StringType(), True), \\\n",
    "     StructField('HPC_delta_e', DoubleType(), True), \\\n",
    "     StructField('HPC_delta_l', DoubleType(), True), \\\n",
    "     StructField('HPC_theta_e', DoubleType(), True), \\\n",
    "     StructField('HPC_theta_l', DoubleType(), True), \\\n",
    "     StructField('HPC_alpha_e', DoubleType(), True), \\\n",
    "     StructField('HPC_alpha_l', DoubleType(), True), \\\n",
    "     StructField('HPC_beta_lo_e', DoubleType(), True), \\\n",
    "     StructField('HPC_beta_lo_l', DoubleType(), True), \\\n",
    "     ])\n",
    "\n",
    "PFC_hf_schema = StructType(\\\n",
    "    [StructField('index', LongType(), True), \\\n",
    "     StructField('trial_n', StringType(), True), \\\n",
    "     StructField('PFC_beta_hi_e', DoubleType(), True), \\\n",
    "     StructField('PFC_beta_hi_l', DoubleType(), True), \\\n",
    "     StructField('PFC_gamma_lo_e', DoubleType(), True), \\\n",
    "     StructField('PFC_gamma_lo_l', DoubleType(), True), \\\n",
    "     StructField('PFC_gamma_mid_e', DoubleType(), True), \\\n",
    "     StructField('PFC_gamma_mid_l', DoubleType(), True), \\\n",
    "     StructField('PFC_gamma_hi_e', DoubleType(), True), \\\n",
    "     StructField('PFC_gamma_hi_l', DoubleType(), True), \\\n",
    "     ])\n",
    "\n",
    "PFC_lf_schema = StructType(\\\n",
    "    [StructField('index', LongType(), True), \\\n",
    "     StructField('trial_n', StringType(), True), \\\n",
    "     StructField('PFC_delta_e', DoubleType(), True), \\\n",
    "     StructField('PFC_delta_l', DoubleType(), True), \\\n",
    "     StructField('PFC_theta_e', DoubleType(), True), \\\n",
    "     StructField('PFC_theta_l', DoubleType(), True), \\\n",
    "     StructField('PFC_alpha_e', DoubleType(), True), \\\n",
    "     StructField('PFC_alpha_l', DoubleType(), True), \\\n",
    "     StructField('PFC_beta_lo_e', DoubleType(), True), \\\n",
    "     StructField('PFC_beta_lo_l', DoubleType(), True), \\\n",
    "     ])\n",
    "\n",
    "ispc_schema = StructType(\\\n",
    "    [StructField('index', LongType(), True), \\\n",
    "     StructField('trial_n', StringType(), True), \\\n",
    "     StructField('theta_ispc_e', DoubleType(), True), \\\n",
    "     StructField('theta_ispc_l', DoubleType(), True), \\\n",
    "     StructField('alpha_ispc_e', DoubleType(), True), \\\n",
    "     StructField('alpha_ispc_l', DoubleType(), True), \\\n",
    "     StructField('beta_lo_ispc_e', DoubleType(), True), \\\n",
    "     StructField('beta_lo_ispc_l', DoubleType(), True), \\\n",
    "     StructField('beta_hi_ispc_e', DoubleType(), True), \\\n",
    "     StructField('beta_hi_ispc_l', DoubleType(), True), \\\n",
    "     StructField('gamma_lo_ispc_e', DoubleType(), True), \\\n",
    "     StructField('gamma_lo_ispc_l', DoubleType(), True), \\\n",
    "     ])\n",
    "\n",
    "pac_schema = StructType(\\\n",
    "    [StructField('index', LongType(), True), \\\n",
    "     StructField('trial_n', StringType(), True), \\\n",
    "     StructField('30Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('30Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('30Hz-10Hz pac', DoubleType(), True), \\\n",
    "     StructField('40Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('40Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('40Hz-10Hz pac', DoubleType(), True), \\\n",
    "     StructField('50Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('50Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('50Hz-10Hz pac', DoubleType(), True), \\\n",
    "     StructField('60Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('60Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('60Hz-10Hz pac', DoubleType(), True), \\\n",
    "     StructField('70Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('70Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('70Hz-10Hz pac', DoubleType(), True), \\\n",
    "     StructField('80Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('80Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('80Hz-10Hz pac', DoubleType(), True), \\\n",
    "     StructField('90Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('90Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('90Hz-10Hz pac', DoubleType(), True), \\\n",
    "     StructField('100Hz-6Hz pac', DoubleType(), True), \\\n",
    "     StructField('100Hz-8Hz pac', DoubleType(), True), \\\n",
    "     StructField('100Hz-10Hz pac', DoubleType(), True), \\\n",
    "     ])\n",
    "\n",
    "# data is split across these 24 smaller csvs\n",
    "# First getting all our Vehicle animals together\n",
    "# coke cue\n",
    "HPC_hf = spark.read.format('csv').option('header', True).schema(HPC_hf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_coke_HPC_high_freq.csv').drop('index')\n",
    "HPC_lf = spark.read.format('csv').option('header', True).schema(HPC_lf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_coke_HPC_low_freq.csv').drop('index')\n",
    "PFC_hf = spark.read.format('csv').option('header', True).schema(PFC_hf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_coke_PFC_high_freq.csv').drop('index')\n",
    "PFC_lf = spark.read.format('csv').option('header', True).schema(PFC_lf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_coke_PFC_low_freq.csv').drop('index')\n",
    "ispc = spark.read.format('csv').option('header', True).schema(ispc_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_coke_PFC_HPC_ispcs.csv').drop('index')\n",
    "pac = spark.read.format('csv').option('header', True).schema(pac_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_coke_PFC_HPC_pac.csv').drop('index')\n",
    "\n",
    "# building cocaine dataframe, with label col: 1 denotes coke cue presentation\n",
    "coc = HPC_hf.join(HPC_lf, on='trial_n').join(PFC_hf, on='trial_n').join(PFC_lf, on='trial_n').join(ispc, on='trial_n').join(pac, on='trial_n')\n",
    "coc = coc.withColumn('cue', f.lit('coke'))\n",
    "\n",
    "# saline cue\n",
    "HPC_hf = spark.read.format('csv').option('header', True).schema(HPC_hf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_saline_HPC_high_freq.csv').drop('index')\n",
    "HPC_lf = spark.read.format('csv').option('header', True).schema(HPC_lf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_saline_HPC_low_freq.csv').drop('index')\n",
    "PFC_hf = spark.read.format('csv').option('header', True).schema(PFC_hf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_saline_PFC_high_freq.csv').drop('index')\n",
    "PFC_lf = spark.read.format('csv').option('header', True).schema(PFC_lf_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_saline_PFC_low_freq.csv').drop('index')\n",
    "ispc = spark.read.format('csv').option('header', True).schema(ispc_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_saline_PFC_HPC_ispcs.csv').drop('index')\n",
    "pac = spark.read.format('csv').option('header', True).schema(pac_schema).load('dbfs:/FileStore/tables/CUE1_Vehicle_saline_PFC_HPC_pac.csv').drop('index')\n",
    "\n",
    "# building saline dataframe, with cue col\n",
    "sal = HPC_hf.join(HPC_lf, on='trial_n').join(PFC_hf, on='trial_n').join(PFC_lf, on='trial_n').join(ispc, on='trial_n').join(pac, on='trial_n')\n",
    "sal = sal.withColumn('cue', f.lit('saline'))\n",
    "\n",
    "# merge the two sets\n",
    "data = coc.union(sal)\n",
    "\n",
    "# split into train and static test sets\n",
    "train, test = data.randomSplit(weights=[0.7,0.3], seed=1234)\n",
    "\n",
    "# check current number of partitions\n",
    "print(test.rdd.getNumPartitions())\n",
    "\n",
    "# repartition into 50 partitions\n",
    "test = test.repartition(50)\n",
    "print(test.rdd.getNumPartitions())\n",
    "\n",
    "# write to directory as 50 separate smaller files to simulate stream\n",
    "dbutils.fs.rm('FileStore/tables/cocaineCue/', True)\n",
    "test.write.format('csv').option('header', True).save('FileStore/tables/cocaineCue/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d1c3b17-6149-4ef6-bcb1-69038d9ded20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b66a76bcfc4769b360d58416f9a98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8491cb60e95401fa911c8abd9423bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier, LogisticRegression, RandomForestClassifier, LinearSVC\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import PCA\n",
    "# cue indexer\n",
    "cueIndexer = StringIndexer(inputCol='cue', outputCol='label')\n",
    "\n",
    "# logistic regression, no tuning\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# toss feature cols (all floats) into vector assembler\n",
    "cols = [c for c in data.columns if not c in set(['index', 'trial_n', 'label', 'cue'])]\n",
    "vecAssem = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "\n",
    "# pipeline\n",
    "myStages = [cueIndexer, vecAssem, lr]\n",
    "\n",
    "p = Pipeline(stages=myStages)\n",
    "\n",
    "# fit pipeline on train data\n",
    "pModel = p.fit(train)\n",
    "\n",
    "# check predictions on training data\n",
    "predTrain = pModel.transform(train)\n",
    "\n",
    "# transform static data with fitted pipeline\n",
    "predTest = pModel.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11410dd2-e3f6-453d-a2bc-7db8767c694a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTrain Confusion Matrix\n   1\t 0\n1  65\t 10\n0  10\t 68\ntrain accuracy: 0.869281045751634\n\nTest Confusion Matrix\n   1\t 0\n1  24\t 19\n0  11\t 21\ntest accuracy: 0.6\n\nTrain area under ROC:  0.8692307692307693\nTest area under ROC:  0.6053571428571428\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "train_predictions = predTrain.select(f.col('prediction'), f.col('label'))\n",
    "test_predictions = predTest.select(f.col('prediction'), f.col('label'))\n",
    "\n",
    "# confusion matrix\n",
    "print('\\nTrain Confusion Matrix')\n",
    "TP = train_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 1)).count()\n",
    "FP = train_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 0)).count()\n",
    "TN = train_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 0)).count()\n",
    "FN = train_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 1)).count()\n",
    "print(f'   1\\t 0\\n1  {TP}\\t {FP}\\n0  {FN}\\t {TN}')\n",
    "print(f'train accuracy: {(TP+TN)/(TP+FP+FN+TN)}')\n",
    "\n",
    "# confusion matrix\n",
    "print('\\nTest Confusion Matrix')\n",
    "TP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 1)).count()\n",
    "FP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 0)).count()\n",
    "TN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 0)).count()\n",
    "FN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 1)).count()\n",
    "print(f'   1\\t 0\\n1  {TP}\\t {FP}\\n0  {FN}\\t {TN}')\n",
    "print(f'test accuracy: {(TP+TN)/(TP+FP+FN+TN)}')\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "print('\\nTrain area under ROC: ', evaluator.evaluate(predTrain))\n",
    "print('Test area under ROC: ', evaluator.evaluate(predTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd34a0cd-4473-441b-8e00-1aaaff1104fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# new schema for compiled dataframe stream\n",
    "cueSchema = StructType([\\\n",
    "    StructField('trial_n', StringType(), True), \\\n",
    "    StructField('HPC_beta_hi_e', DoubleType(), True), \\\n",
    "    StructField('HPC_beta_hi_l', DoubleType(), True), \\\n",
    "    StructField('HPC_gamma_lo_e', DoubleType(), True), \\\n",
    "    StructField('HPC_gamma_lo_l', DoubleType(), True), \\\n",
    "    StructField('HPC_gamma_mid_e', DoubleType(), True), \\\n",
    "    StructField('HPC_gamma_mid_l', DoubleType(), True), \\\n",
    "    StructField('HPC_gamma_hi_e', DoubleType(), True), \\\n",
    "    StructField('HPC_gamma_hi_l', DoubleType(), True), \\\n",
    "    StructField('HPC_delta_e', DoubleType(), True), \\\n",
    "    StructField('HPC_delta_l', DoubleType(), True), \\\n",
    "    StructField('HPC_theta_e', DoubleType(), True), \\\n",
    "    StructField('HPC_theta_l', DoubleType(), True), \\\n",
    "    StructField('HPC_alpha_e', DoubleType(), True), \\\n",
    "    StructField('HPC_alpha_l', DoubleType(), True), \\\n",
    "    StructField('HPC_beta_lo_e', DoubleType(), True), \\\n",
    "    StructField('HPC_beta_lo_l', DoubleType(), True), \\\n",
    "    StructField('PFC_beta_hi_e', DoubleType(), True), \\\n",
    "    StructField('PFC_beta_hi_l', DoubleType(), True), \\\n",
    "    StructField('PFC_gamma_lo_e', DoubleType(), True), \\\n",
    "    StructField('PFC_gamma_lo_l', DoubleType(), True), \\\n",
    "    StructField('PFC_gamma_mid_e', DoubleType(), True), \\\n",
    "    StructField('PFC_gamma_mid_l', DoubleType(), True), \\\n",
    "    StructField('PFC_gamma_hi_e', DoubleType(), True), \\\n",
    "    StructField('PFC_gamma_hi_l', DoubleType(), True), \\\n",
    "    StructField('PFC_delta_e', DoubleType(), True), \\\n",
    "    StructField('PFC_delta_l', DoubleType(), True), \\\n",
    "    StructField('PFC_theta_e', DoubleType(), True), \\\n",
    "    StructField('PFC_theta_l', DoubleType(), True), \\\n",
    "    StructField('PFC_alpha_e', DoubleType(), True), \\\n",
    "    StructField('PFC_alpha_l', DoubleType(), True), \\\n",
    "    StructField('PFC_beta_lo_e', DoubleType(), True), \\\n",
    "    StructField('PFC_beta_lo_l', DoubleType(), True), \\\n",
    "    StructField('theta_ispc_e', DoubleType(), True), \\\n",
    "    StructField('theta_ispc_l', DoubleType(), True), \\\n",
    "    StructField('alpha_ispc_e', DoubleType(), True), \\\n",
    "    StructField('alpha_ispc_l', DoubleType(), True), \\\n",
    "    StructField('beta_lo_ispc_e', DoubleType(), True), \\\n",
    "    StructField('beta_lo_ispc_l', DoubleType(), True), \\\n",
    "    StructField('beta_hi_ispc_e', DoubleType(), True), \\\n",
    "    StructField('beta_hi_ispc_l', DoubleType(), True), \\\n",
    "    StructField('gamma_lo_ispc_e', DoubleType(), True), \\\n",
    "    StructField('gamma_lo_ispc_l', DoubleType(), True), \\\n",
    "    StructField('30Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('30Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('30Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('40Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('40Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('40Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('50Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('50Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('50Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('60Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('60Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('60Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('70Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('70Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('70Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('80Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('80Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('80Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('90Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('90Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('90Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('100Hz-6Hz pac', DoubleType(), True), \\\n",
    "    StructField('100Hz-8Hz pac', DoubleType(), True), \\\n",
    "    StructField('100Hz-10Hz pac', DoubleType(), True), \\\n",
    "    StructField('cue', StringType(), True) \\\n",
    "])\n",
    "\n",
    "# source\n",
    "sourceStream = spark.readStream.format('csv') \\\n",
    "    .option('encoding', 'UTF-8') \\\n",
    "    .option('header', True) \\\n",
    "    .schema(cueSchema) \\\n",
    "    .option('maxFilesPerTrigger', 1) \\\n",
    "    .load('dbfs:/FileStore/tables/cocaineCue')\n",
    "\n",
    "# fit model to stream\n",
    "predTestStream = pModel.transform(sourceStream)\n",
    "\n",
    "# sink, outputMode append, not complete since we are not aggregating\n",
    "sinkStream = predTestStream.writeStream.outputMode('append') \\\n",
    "    .format('memory') \\\n",
    "    .queryName('testPreds') \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba09f02-5e87-4fff-9061-64ef599f4ecb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+\n|             trial_n|prediction|label|\n+--------------------+----------+-----+\n| Ephys5_rat1_trial52|       0.0|  0.0|\n| Ephys9_rat1_trial31|       0.0|  0.0|\n| Ephys9_rat1_trial25|       0.0|  0.0|\n|  Ephys9_rat1_trial5|       0.0|  0.0|\n|Ephys11_rat1_trial14|       1.0|  0.0|\n| Ephys5_rat1_trial26|       1.0|  1.0|\n+--------------------+----------+-----+\n\n\nTest Confusion Matrix\n   1\t 0\n1  1\t 1\n0  0\t 4\nTest accuracy: 0.8333333333333334\nTest area under ROC:  0.9\n"
     ]
    }
   ],
   "source": [
    "# evaluate early on in the stream\n",
    "df_preds = spark.sql(\"select trial_n, prediction, label from testPreds\")\n",
    "df_preds.show()\n",
    "# evaluate\n",
    "test_predictions = df_preds.select(f.col('prediction'), f.col('label'))\n",
    "\n",
    "# confusion matrix\n",
    "print('\\nTest Confusion Matrix')\n",
    "TP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 1)).count()\n",
    "FP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 0)).count()\n",
    "TN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 0)).count()\n",
    "FN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 1)).count()\n",
    "print(f'   1\\t 0\\n1  {TP}\\t {FP}\\n0  {FN}\\t {TN}')\n",
    "print(f'Test accuracy: {(TP+TN)/(TP+FP+FN+TN)}')\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "print('Test area under ROC: ', evaluator.evaluate(df_preds.select(f.col('prediction').cast('double'), f.col('label').cast('double'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f108bb6-3303-4ec0-9fdd-f17dbbe4ffb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+\n|             trial_n|prediction|label|\n+--------------------+----------+-----+\n| Ephys5_rat1_trial52|       0.0|  0.0|\n| Ephys9_rat1_trial31|       0.0|  0.0|\n| Ephys9_rat1_trial25|       0.0|  0.0|\n|  Ephys9_rat1_trial5|       0.0|  0.0|\n|Ephys11_rat1_trial14|       1.0|  0.0|\n| Ephys5_rat1_trial26|       1.0|  1.0|\n| Ephys5_rat1_trial22|       1.0|  0.0|\n| Ephys11_rat1_trial9|       1.0|  1.0|\n| Ephys11_rat1_trial7|       0.0|  0.0|\n| Ephys9_rat1_trial13|       1.0|  1.0|\n|Ephys11_rat1_trial11|       1.0|  0.0|\n| Ephys5_rat1_trial35|       1.0|  1.0|\n| Ephys5_rat1_trial10|       0.0|  0.0|\n|Ephys11_rat1_trial11|       1.0|  1.0|\n| Ephys5_rat1_trial12|       1.0|  0.0|\n| Ephys6_rat1_trial18|       1.0|  1.0|\n| Ephys5_rat1_trial45|       0.0|  0.0|\n| Ephys9_rat1_trial24|       1.0|  1.0|\n| Ephys5_rat1_trial26|       0.0|  0.0|\n|  Ephys6_rat1_trial2|       0.0|  1.0|\n+--------------------+----------+-----+\nonly showing top 20 rows\n\n\nTest Confusion Matrix\n   1\t 0\n1  22\t 10\n0  8\t 14\nTest accuracy: 0.6666666666666666\nTest area under ROC:  0.6583333333333333\n"
     ]
    }
   ],
   "source": [
    "# as we evaluate later in the stream, the results approach results of static window\n",
    "df_preds = spark.sql(\"select trial_n, prediction, label from testPreds\")\n",
    "df_preds.show()\n",
    "# evaluate\n",
    "test_predictions = df_preds.select(f.col('prediction'), f.col('label'))\n",
    "\n",
    "# confusion matrix\n",
    "print('\\nTest Confusion Matrix')\n",
    "TP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 1)).count()\n",
    "FP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 0)).count()\n",
    "TN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 0)).count()\n",
    "FN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 1)).count()\n",
    "print(f'   1\\t 0\\n1  {TP}\\t {FP}\\n0  {FN}\\t {TN}')\n",
    "print(f'Test accuracy: {(TP+TN)/(TP+FP+FN+TN)}')\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "print('Test area under ROC: ', evaluator.evaluate(df_preds.select(f.col('prediction').cast('double'), f.col('label').cast('double'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f53e209-4c57-4fc0-83df-5e1765cfb84b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+\n|             trial_n|prediction|label|\n+--------------------+----------+-----+\n| Ephys5_rat1_trial52|       0.0|  0.0|\n| Ephys9_rat1_trial31|       0.0|  0.0|\n| Ephys9_rat1_trial25|       0.0|  0.0|\n|  Ephys9_rat1_trial5|       0.0|  0.0|\n|Ephys11_rat1_trial14|       1.0|  0.0|\n| Ephys5_rat1_trial26|       1.0|  1.0|\n| Ephys5_rat1_trial22|       1.0|  0.0|\n| Ephys11_rat1_trial9|       1.0|  1.0|\n| Ephys11_rat1_trial7|       0.0|  0.0|\n| Ephys9_rat1_trial13|       1.0|  1.0|\n|Ephys11_rat1_trial11|       1.0|  0.0|\n| Ephys5_rat1_trial35|       1.0|  1.0|\n| Ephys5_rat1_trial10|       0.0|  0.0|\n|Ephys11_rat1_trial11|       1.0|  1.0|\n| Ephys5_rat1_trial12|       1.0|  0.0|\n| Ephys6_rat1_trial18|       1.0|  1.0|\n| Ephys5_rat1_trial45|       0.0|  0.0|\n| Ephys9_rat1_trial24|       1.0|  1.0|\n| Ephys5_rat1_trial26|       0.0|  0.0|\n|  Ephys6_rat1_trial2|       0.0|  1.0|\n+--------------------+----------+-----+\nonly showing top 20 rows\n\n\nTest Confusion Matrix\n   1\t 0\n1  24\t 19\n0  11\t 21\nTest accuracy: 0.6\nTest area under ROC:  0.6053571428571428\n"
     ]
    }
   ],
   "source": [
    "# as we evaluate later in the stream, the results approach results of static window\n",
    "df_preds = spark.sql(\"select trial_n, prediction, label from testPreds\")\n",
    "df_preds.show()\n",
    "# evaluate\n",
    "test_predictions = df_preds.select(f.col('prediction'), f.col('label'))\n",
    "\n",
    "# confusion matrix\n",
    "print('\\nTest Confusion Matrix')\n",
    "TP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 1)).count()\n",
    "FP = test_predictions.filter((f.col('prediction') == 1) & (f.col('label') == 0)).count()\n",
    "TN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 0)).count()\n",
    "FN = test_predictions.filter((f.col('prediction') == 0) & (f.col('label') == 1)).count()\n",
    "print(f'   1\\t 0\\n1  {TP}\\t {FP}\\n0  {FN}\\t {TN}')\n",
    "print(f'Test accuracy: {(TP+TN)/(TP+FP+FN+TN)}')\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "print('Test area under ROC: ', evaluator.evaluate(df_preds.select(f.col('prediction').cast('double'), f.col('label').cast('double'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "952df142-0af1-4f8d-9b03-791f2cea05ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "COMP4334_Assignment2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
